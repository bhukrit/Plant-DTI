{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################################################################\n",
    "#\n",
    "#   Copyright Â© 2022 Center for Agricultural Systems Biology\n",
    "#   Authorships: Ruengsrichaiya B., Nukoolkit C., Kalapanulak S. and Saithong T., \n",
    "#   (202x) Plant-DTI: Extending the landscape of TF protein and DNA interaction in plants by a machine learning-based approach. \n",
    "#   xxxxx., xx, xxx. (in preperation). \n",
    "#   Contact: bhukrit.r@mail.kmutt.ac.th\n",
    "#\n",
    "###############################################################################################################################\n",
    "#\n",
    "#   Pseudocode for model Plant-DTI model construction with Random Forest classifier using scikit learn: \n",
    "#   Classes labeled  are 1 (interacted) and 0 (not interacted)\n",
    "#   Random within models (RW) are avaiable for TFBS length range from 7-15 bp.\n",
    "#   Random pairs models (RP) are avaiable for TFBS length range from 7-14 bp.\n",
    "#\n",
    "###############################################################################################################################\n",
    "#\n",
    "#   Random pairs models (RP)\n",
    "#\n",
    "###############################################################################################################################\n",
    "\n",
    "INPUT: Feature of train data, feature of traintest data, class label of train data and, class label of test data\n",
    "OUTPUT: Plant-DTI model and its performances.\n",
    "    \n",
    "BEGIN\n",
    "FOR i = 7 to 15 do\n",
    "    Read feature of train data\n",
    "    Read class label of train data\n",
    "    Read features of test data\n",
    "    Read class label of test data\n",
    "\n",
    "    Train model using random forest classifier from scikit learn with number of trees = 100\n",
    "    Save trained model in .sav file\n",
    "\n",
    "    Predict features of test data by using trained random forest model\n",
    "    Evaluate model performance by compare predicted result with label of test data\n",
    "    Collect model performance results\n",
    "END FOR loop\n",
    "Write summary model performance in .csv file\n",
    "END\n",
    "\n",
    "##############################################################################################################################\n",
    "#\n",
    "#   Random within models (RW)\n",
    "#\n",
    "##############################################################################################################################\n",
    "\n",
    "INPUT: Feature of train data, feature of traintest data, class label of train data and, class label of test data\n",
    "OUTPUT: Plant-DTI model and its performances.\n",
    "    \n",
    "BEGIN\n",
    "FOR i = 7 to 14 do\n",
    "    read features of train data\n",
    "    Read class label of train data\n",
    "    Read features of test data\n",
    "    Read class labels of test data\n",
    "\n",
    "    Train model using random forest classifier from scikit learn with number of trees= 100\n",
    "    Save trained model in .sav file\n",
    "\n",
    "    Predict features of test data by using trained random forest model\n",
    "    Evaluate model performance by compare predicted result with label of test data\n",
    "    Collect model performance results\n",
    "END FOR loop\n",
    "Write summary model performance in .csv file\n",
    "END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import all required library\n",
    "import pandas as pd  \n",
    "import numpy as np  \n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import pickle\n",
    "\n",
    "from textwrap import wrap\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score,  classification_report\n",
    "\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "class color:\n",
    "   PURPLE = '\\033[95m'\n",
    "   CYAN = '\\033[96m'\n",
    "   DARKCYAN = '\\033[36m'\n",
    "   BLUE = '\\033[94m'\n",
    "   GREEN = '\\033[92m'\n",
    "   YELLOW = '\\033[93m'\n",
    "   RED = '\\033[91m'\n",
    "   BOLD = '\\033[1m'\n",
    "   UNDERLINE = '\\033[4m'\n",
    "   END = '\\033[0m'\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TN</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>TP</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall (Sensitivity)</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>NPV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2872</td>\n",
       "      <td>17</td>\n",
       "      <td>11</td>\n",
       "      <td>2877</td>\n",
       "      <td>0.995153</td>\n",
       "      <td>0.994126</td>\n",
       "      <td>0.996191</td>\n",
       "      <td>0.995157</td>\n",
       "      <td>0.994116</td>\n",
       "      <td>0.996185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     TN  FP  FN    TP  Accuracy  Precision  Recall (Sensitivity)  F1-score  \\\n",
       "0  2872  17  11  2877  0.995153   0.994126              0.996191  0.995157   \n",
       "\n",
       "   Specificity       NPV  \n",
       "0     0.994116  0.996185  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Code for model construction, Random Forest with 100 trees: Random within (RW)\n",
    "\n",
    "#Create dataframe for collecting model performance results\n",
    "report_summary_df = pd.DataFrame(columns=['TN','FP','FN','TP','Accuracy','Precision', 'Recall (Sensitivity)',\n",
    "                 'F1-score','Specificity', 'NPV'])\n",
    "\n",
    "for i in range(7,16):\n",
    "    #read train_data\n",
    "    X_train = pd.read_csv('Data/train_data/70_holdout_X_train_len' + str(i) +  '_RW.csv')\n",
    "    Y_train = pd.read_csv('Data/train_data/70_holdout_Y_train_len' + str(i) + '_RW.csv')\n",
    "\n",
    "    #read test_data\n",
    "    X_test = pd.read_csv('Data/test_data/30_holdout_X_test_len' + str(i) + '_RW.csv')\n",
    "    Y_test = pd.read_csv('Data/test_data/30_holdout_Y_test_len' + str(i) + '_RW.csv')\n",
    "\n",
    "\n",
    "    #Model training data with RF classifier (100 trees)\n",
    "    rf_clf=RandomForestClassifier(n_estimators= 100,random_state= 100,oob_score=True)\n",
    "    rf_clf= rf_clf.fit(X_train, Y_train['class'])\n",
    "\n",
    "    #save model .sav\n",
    "    pickle.dump(rf_clf, open('OUTPUT/model_RW_len' + str(i) + '.sav', 'wb'))\n",
    "\n",
    "\n",
    "    #Predict test dataset\n",
    "    Y_pred = rf_clf.predict(X_test)\n",
    "    \n",
    "    #collect model performance (confusion matrix, accuracy, precision, sensitivity, f1-score, specificity, npv)\n",
    "    #confusion matrix\n",
    "    confuse_mat=list(confusion_matrix(Y_test, Y_pred).ravel())\n",
    "    \n",
    "    \n",
    "    acc=accuracy_score(Y_test, Y_pred)\n",
    "    precision=np.ndarray.tolist(precision_score(Y_test, Y_pred, average = None))\n",
    "    recall=np.ndarray.tolist(recall_score(Y_test, Y_pred, average = None))\n",
    "    f1=np.ndarray.tolist(f1_score(Y_test, Y_pred, average = None))\n",
    "    \n",
    "    #classification report for specificity and npv\n",
    "    class_report_dict=classification_report(Y_test, Y_pred, digits=4, output_dict=True)\n",
    "    specificity=class_report_dict['0']['recall']\n",
    "    npv=class_report_dict['0']['precision']\n",
    "    \n",
    "    report=[]\n",
    "    report.append(confuse_mat[0]) #TN\n",
    "    report.append(confuse_mat[1]) #FP\n",
    "    report.append(confuse_mat[2]) #FN\n",
    "    report.append(confuse_mat[3]) #TP\n",
    "    report.append(acc)\n",
    "    report.append(precision[1])\n",
    "    report.append(recall[1])\n",
    "    report.append(f1[1])\n",
    "    report.append(specificity)\n",
    "    report.append(npv)\n",
    "    report_df = pd.DataFrame([report], columns=['TN','FP','FN','TP','Accuracy','Precision', 'Recall (Sensitivity)',\n",
    "                 'F1-score','Specificity', 'NPV'])\n",
    "    report_summary_df = pd.concat([report_summary_df, report_df])\n",
    "\n",
    "report_summary_df.to_csv('OUTPUT/model_RW_performance.csv')\n",
    "report_summary_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TN</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>TP</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall (Sensitivity)</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>NPV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>186</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>191</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.955</td>\n",
       "      <td>0.979487</td>\n",
       "      <td>0.967089</td>\n",
       "      <td>0.953846</td>\n",
       "      <td>0.978947</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    TN FP FN   TP  Accuracy  Precision  Recall (Sensitivity)  F1-score  \\\n",
       "0  186  9  4  191  0.966667      0.955              0.979487  0.967089   \n",
       "\n",
       "   Specificity       NPV  \n",
       "0     0.953846  0.978947  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Code for model construction, Random Forest with 100 trees: Random pairs (RP)\n",
    "\n",
    "#Create dataframe for collecting model performance results\n",
    "report_summary_df = pd.DataFrame(columns=['TN','FP','FN','TP','Accuracy','Precision', 'Recall (Sensitivity)',\n",
    "                 'F1-score','Specificity', 'NPV'])\n",
    "\n",
    "for i in range(7,15):\n",
    "    #read train_data\n",
    "    X_train = pd.read_csv('Data/train_data/70_holdout_X_train_len' + str(i) +  '_RP.csv')\n",
    "    Y_train = pd.read_csv('Data/train_data/70_holdout_Y_train_len' + str(i) + '_RP.csv')\n",
    "\n",
    "    #read test_data\n",
    "    X_test = pd.read_csv('Data/test_data/30_holdout_X_test_len' + str(i) + '_RP.csv')\n",
    "    Y_test = pd.read_csv('Data/test_data/30_holdout_Y_test_len' + str(i) + '_RP.csv')\n",
    "\n",
    "\n",
    "    #Model training data with RF classifier (100 trees)\n",
    "    rf_clf=RandomForestClassifier(n_estimators= 100,random_state= 100,oob_score=True)\n",
    "    rf_clf= rf_clf.fit(X_train, Y_train['class'])\n",
    "\n",
    "    #save model .sav\n",
    "    pickle.dump(rf_clf, open('OUTPUT/model_RP_len' + str(i) + '.sav', 'wb'))\n",
    "\n",
    "\n",
    "    #Predict test dataset\n",
    "    Y_pred = rf_clf.predict(X_test)\n",
    "    \n",
    "    #collect model performance (confusion matrix, accuracy, precision, sensitivity, f1-score, specificity, npv)\n",
    "    #confusion matrix\n",
    "    confuse_mat=list(confusion_matrix(Y_test, Y_pred).ravel())\n",
    "    \n",
    "    \n",
    "    acc=accuracy_score(Y_test, Y_pred)\n",
    "    precision=np.ndarray.tolist(precision_score(Y_test, Y_pred, average = None))\n",
    "    recall=np.ndarray.tolist(recall_score(Y_test, Y_pred, average = None))\n",
    "    f1=np.ndarray.tolist(f1_score(Y_test, Y_pred, average = None))\n",
    "    \n",
    "    #classification report for specificity and npv\n",
    "    class_report_dict=classification_report(Y_test, Y_pred, digits=4, output_dict=True)\n",
    "    specificity=class_report_dict['0']['recall']\n",
    "    npv=class_report_dict['0']['precision']\n",
    "    \n",
    "    report=[]\n",
    "    report.append(confuse_mat[0]) #TN\n",
    "    report.append(confuse_mat[1]) #FP\n",
    "    report.append(confuse_mat[2]) #FN\n",
    "    report.append(confuse_mat[3]) #TP\n",
    "    report.append(acc)\n",
    "    report.append(precision[1])\n",
    "    report.append(recall[1])\n",
    "    report.append(f1[1])\n",
    "    report.append(specificity)\n",
    "    report.append(npv)\n",
    "    report_df = pd.DataFrame([report], columns=['TN','FP','FN','TP','Accuracy','Precision', 'Recall (Sensitivity)',\n",
    "                 'F1-score','Specificity', 'NPV'])\n",
    "    report_summary_df = pd.concat([report_summary_df, report_df])\n",
    "\n",
    "report_summary_df.to_csv('OUTPUT/model_RP_performance.csv')\n",
    "report_summary_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################################################################\n",
    "#\n",
    "#   Copyright Â© 2022 Center for Agricultural Systems Biology\n",
    "#   Authorships: Ruengsrichaiya B., Nukoolkit C., Kalapanulak S. and Saithong T., \n",
    "#   (202x) Plant-DTI: Extending the landscape of TF protein and DNA interaction in plants by a machine learning-based approach. \n",
    "#   xxxxx., xx, xxx. (in preperation). \n",
    "#   Contact: bhukrit.r@mail.kmutt.ac.th\n",
    "#\n",
    "##############################################################################################################################\n",
    "#   \n",
    "#   Pseudocode for model hyperparameter tuning with Random Forest classifier using scikit learn:\n",
    "#   Automatically optimized hyperparameter of each model using GridSearchCV package\n",
    "#   Classes labeled  are 1 (interacted) and 0 (not interacted)\n",
    "#   Random within models (RW) are avaiable for TFBS length range from 7-15 bp.\n",
    "#   Random pairs models (RP) are avaiable for TFBS length range from 7-14 bp.\n",
    "#\n",
    "##############################################################################################################################\n",
    "#\n",
    "#   Random pairs models (RP)\n",
    "#\n",
    "##############################################################################################################################\n",
    "\n",
    "INPUT: Feature of train data, feature of traintest data, class label of train data and, class label of test data\n",
    "OUTPUT: Hyperparameters of Plant-DTI model and its performances.\n",
    "    \n",
    "BEGIN\n",
    "for i = 7 to 14 do\n",
    "    read features of train data\n",
    "    read class label of train data\n",
    "    read features of test data\n",
    "    read class labels of test data\n",
    "\n",
    "    SET model to RandomForestClassifier\n",
    "    SET number of trees range from 1 to 150\n",
    "    SET number of kfold cross validation to 10\n",
    "    Automatically optimize the model using GridSearchCV\n",
    "    Collect GridSearch results in .csv file\n",
    "END\n",
    "\n",
    "##############################################################################################################################\n",
    "#\n",
    "#   Random within models (RW)\n",
    "#\n",
    "##############################################################################################################################\n",
    "\n",
    "INPUT: Feature of train data, feature of traintest data, class label of train data and, class label of test data\n",
    "OUTPUT: Hyperparameters of Plant-DTI model and its performances.\n",
    "    \n",
    "BEGIN\n",
    "FOR i = 7 to 15 do\n",
    "    Read features of train data\n",
    "    Read class label of train data\n",
    "    Read features of test data\n",
    "    Read class label of test data\n",
    "\n",
    "    SET model to RandomForestClassifier\n",
    "    SET number of trees range from 1 to 150\n",
    "    SET number of kfold cross validation to 10\n",
    "    Automatically optimize the model using GridSearchCV\n",
    "    Collect GridSearch results in .csv file\n",
    "END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.008278</td>\n",
       "      <td>0.001612</td>\n",
       "      <td>0.005086</td>\n",
       "      <td>0.000940</td>\n",
       "      <td>1</td>\n",
       "      <td>{'n_estimators': 1}</td>\n",
       "      <td>0.977778</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.936170</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.931818</td>\n",
       "      <td>0.946237</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.936170</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.943904</td>\n",
       "      <td>0.019162</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.023038</td>\n",
       "      <td>0.003848</td>\n",
       "      <td>0.006084</td>\n",
       "      <td>0.001041</td>\n",
       "      <td>6</td>\n",
       "      <td>{'n_estimators': 6}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.989011</td>\n",
       "      <td>0.946237</td>\n",
       "      <td>0.934783</td>\n",
       "      <td>0.977778</td>\n",
       "      <td>0.968421</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.919540</td>\n",
       "      <td>0.977273</td>\n",
       "      <td>0.960290</td>\n",
       "      <td>0.025123</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.008278      0.001612         0.005086        0.000940   \n",
       "1       0.023038      0.003848         0.006084        0.001041   \n",
       "\n",
       "  param_n_estimators               params  split0_test_score  \\\n",
       "0                  1  {'n_estimators': 1}           0.977778   \n",
       "1                  6  {'n_estimators': 6}           1.000000   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0           0.978261           0.936170           0.913043           0.931818   \n",
       "1           0.989011           0.946237           0.934783           0.977778   \n",
       "\n",
       "   split5_test_score  split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0           0.946237           0.945055           0.936170           0.933333   \n",
       "1           0.968421           0.933333           0.956522           0.919540   \n",
       "\n",
       "   split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0           0.941176         0.943904        0.019162                2  \n",
       "1           0.977273         0.960290        0.025123                1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Code for tuning hyperparameter: number of trees from 1 to 150: Random Pairs (RP) \n",
    "\n",
    "for i in range(7,15):\n",
    "    #read train_data\n",
    "    X_train = pd.read_csv('Data/train_data/70_holdout_X_train_len' + str(i) + '_RP.csv')\n",
    "    Y_train = pd.read_csv('Data/train_data/70_holdout_Y_train_len' + str(i) + '_RP.csv')\n",
    "\n",
    "    #read test_data\n",
    "    X_test = pd.read_csv('Data/test_data/30_holdout_X_test_len' + str(i) + '_RP.csv')\n",
    "    Y_test = pd.read_csv('Data/test_data/30_holdout_Y_test_len' + str(i) + '_RP.csv')\n",
    "\n",
    "\n",
    "    #Random forrest tune\n",
    "    model = RandomForestClassifier(random_state=100)\n",
    "    n_estimators = range(1, 150, 1)\n",
    "    param_grid = dict(n_estimators=n_estimators)\n",
    "    kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=100)\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=kfold, scoring=\"f1\")\n",
    "    grid_result = grid_search.fit(X_train, Y_train['class'])\n",
    "\n",
    "\n",
    "\n",
    "    ##Create file for collect results\n",
    "    best_para=str(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "    means = grid_result.cv_results_['mean_test_score']\n",
    "    stds = grid_result.cv_results_['std_test_score']\n",
    "    params = grid_result.cv_results_['params']\n",
    "\n",
    "    report_tune_df=pd.DataFrame(grid_result.cv_results_)\n",
    "    report_tune_df.to_csv('OUTPUT/'+ 'model_RP_len' + str(i) + '_tuned_result.csv', index=False)\n",
    "\n",
    "#output à¸à¸µà¹ show à¹à¸à¹à¸à¸à¸±à¸§à¸­à¸¢à¹à¸²à¸à¹à¸à¸¢ à¹ à¸à¸°à¸à¸£à¸±à¸ à¸à¸£à¸´à¸ à¹ n_estimators à¸à¸°à¸à¸±à¹à¸à¹à¸à¹ 1-150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.027127</td>\n",
       "      <td>0.002849</td>\n",
       "      <td>0.006985</td>\n",
       "      <td>0.001336</td>\n",
       "      <td>1</td>\n",
       "      <td>{'n_estimators': 1}</td>\n",
       "      <td>0.982301</td>\n",
       "      <td>0.973646</td>\n",
       "      <td>0.974321</td>\n",
       "      <td>0.977289</td>\n",
       "      <td>0.979351</td>\n",
       "      <td>0.973607</td>\n",
       "      <td>0.979442</td>\n",
       "      <td>0.980249</td>\n",
       "      <td>0.978534</td>\n",
       "      <td>0.983776</td>\n",
       "      <td>0.978252</td>\n",
       "      <td>0.003358</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.116688</td>\n",
       "      <td>0.011918</td>\n",
       "      <td>0.009479</td>\n",
       "      <td>0.002463</td>\n",
       "      <td>6</td>\n",
       "      <td>{'n_estimators': 6}</td>\n",
       "      <td>0.997776</td>\n",
       "      <td>0.991124</td>\n",
       "      <td>0.996299</td>\n",
       "      <td>0.995556</td>\n",
       "      <td>0.997028</td>\n",
       "      <td>0.995556</td>\n",
       "      <td>0.998516</td>\n",
       "      <td>0.995549</td>\n",
       "      <td>0.997037</td>\n",
       "      <td>0.995549</td>\n",
       "      <td>0.995999</td>\n",
       "      <td>0.001905</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.027127      0.002849         0.006985        0.001336   \n",
       "1       0.116688      0.011918         0.009479        0.002463   \n",
       "\n",
       "  param_n_estimators               params  split0_test_score  \\\n",
       "0                  1  {'n_estimators': 1}           0.982301   \n",
       "1                  6  {'n_estimators': 6}           0.997776   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0           0.973646           0.974321           0.977289           0.979351   \n",
       "1           0.991124           0.996299           0.995556           0.997028   \n",
       "\n",
       "   split5_test_score  split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0           0.973607           0.979442           0.980249           0.978534   \n",
       "1           0.995556           0.998516           0.995549           0.997037   \n",
       "\n",
       "   split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0           0.983776         0.978252        0.003358                2  \n",
       "1           0.995549         0.995999        0.001905                1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Code for tuning hyperparameter: number of trees from 1 to 150: Random Pairs (RW)\n",
    "\n",
    "\n",
    "for i in range(7,16):\n",
    "    #read train_data\n",
    "    X_train = pd.read_csv('Data/train_data/70_holdout_X_train_len' + str(i) + '_RW.csv')\n",
    "    Y_train = pd.read_csv('Data/train_data/70_holdout_Y_train_len' + str(i) + '_RW.csv')\n",
    "\n",
    "    #read test_data\n",
    "    X_test = pd.read_csv('Data/test_data/30_holdout_X_test_len' + str(i) + '_RW.csv')\n",
    "    Y_test = pd.read_csv('Data/test_data/30_holdout_Y_test_len' + str(i) + '_RW.csv')\n",
    "\n",
    "\n",
    "    #Random forrest tune\n",
    "    model = RandomForestClassifier(random_state=100)\n",
    "    n_estimators = range(1, 150, 1)\n",
    "    param_grid = dict(n_estimators=n_estimators)\n",
    "    kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=100)\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=kfold, scoring=\"f1\")\n",
    "    grid_result = grid_search.fit(X_train, Y_train['class'])\n",
    "\n",
    "\n",
    "\n",
    "    ##Create file for collect results\n",
    "    best_para=str(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "    means = grid_result.cv_results_['mean_test_score']\n",
    "    stds = grid_result.cv_results_['std_test_score']\n",
    "    params = grid_result.cv_results_['params']\n",
    "\n",
    "    report_tune_df=pd.DataFrame(grid_result.cv_results_)\n",
    "    report_tune_df.to_csv('OUTPUT/'+ 'model_RW_len' + str(i) + '_tuned_result.csv', index=False)\n",
    "\n",
    "#output à¸à¸µà¹ show à¹à¸à¹à¸à¸à¸±à¸§à¸­à¸¢à¹à¸²à¸à¹à¸à¸¢ à¹ à¸à¸°à¸à¸£à¸±à¸ à¸à¸£à¸´à¸ à¹ n_estimators à¸à¸°à¸à¸±à¹à¸à¹à¸à¹ 1-150"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
